{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on https://github.com/uygarkurt/DDPM-Image-Generation/blob/main/DDPM_Image_Generartion.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.models import inception_v3\n",
    "from torchvision.transforms import ToTensor, Resize, Normalize, Compose\n",
    "\n",
    "\n",
    "from diffusers import UNet2DModel, DDPMScheduler, DDPMPipeline\n",
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import timeit\n",
    "import json\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "\n",
    "# ignore UserWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "IMG_SIZE = 96\n",
    "DATASET_PERCENTAGE = 0.01\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 50\n",
    "NUM_GENERATE_IMAGES = 9\n",
    "NUM_TIMESTEPS = 500\n",
    "MIXED_PRECISION = \"fp16\"\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2064e25523054d1b9885697a7ee804f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/3031 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecbbb93dcdc144fcb59e4b59570ba1f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/3031 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f414db3b8814ba7998bed66e0448e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "local_dataset_path = f\"data/square{IMG_SIZE}_random{str(DATASET_PERCENTAGE)}/\"\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=local_dataset_path)\n",
    "dataset = dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(examples):\n",
    "    images = [preprocess(image.convert(\"RGB\")) for image in examples[\"image\"]]\n",
    "    return {\"images\": images}\n",
    "\n",
    "\n",
    "dataset.set_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_small = UNet2DModel(\n",
    "    sample_size=IMG_SIZE,\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    layers_per_block=1,\n",
    "    block_out_channels=(64, 64, 128, 128, 256),\n",
    "    down_block_types=(\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"AttnDownBlock2D\",\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"AttnUpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "    ),\n",
    ")\n",
    "model_small = model_small.to(device)\n",
    "\n",
    "model_mid = UNet2DModel(\n",
    "    sample_size=IMG_SIZE,\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    layers_per_block=2,\n",
    "    block_out_channels=(128, 128, 256, 256, 512, 512),\n",
    "    down_block_types=(\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"AttnDownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"UpBlock2D\",\n",
    "        \"AttnUpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "    ),\n",
    ")\n",
    "model_mid = model_mid.to(device)\n",
    "\n",
    "\n",
    "model_big = UNet2DModel(\n",
    "    sample_size=IMG_SIZE,\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    layers_per_block=3,\n",
    "    block_out_channels=(128, 256, 256, 512, 512, 1024, 1024),\n",
    "    down_block_types=(\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"AttnDownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"AttnUpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "    ),\n",
    ")\n",
    "model_big = model_big.to(device)\n",
    "models = [model_small, model_mid, model_big]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2):\n",
    "    \"\"\"Calculate the FrÃ©chet Distance between two multivariate Gaussians.\"\"\"\n",
    "    covmean, _ = sqrtm(sigma1 @ sigma2, disp=False)\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "\n",
    "    diff = mu1 - mu2\n",
    "    return diff @ diff + np.trace(sigma1 + sigma2 - 2 * covmean)\n",
    "\n",
    "\n",
    "def get_activations(model, dataloader, device, key):\n",
    "    \"\"\"Get activations of the dataset images using the InceptionV3 model.\"\"\"\n",
    "    model.eval()\n",
    "    activations = []\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Calculating activations\", leave=False):\n",
    "        images = batch[key].to(device)\n",
    "        with torch.no_grad():\n",
    "            preds = model(images)\n",
    "        activations.append(preds.cpu().numpy())\n",
    "\n",
    "    activations = np.concatenate(activations, axis=0)\n",
    "    return activations\n",
    "\n",
    "\n",
    "def calculate_statistics(activations):\n",
    "    \"\"\"Calculate mean and covariance matrix of activations.\"\"\"\n",
    "    mu = np.mean(activations, axis=0)\n",
    "    sigma = np.cov(activations, rowvar=False)\n",
    "    return mu, sigma\n",
    "\n",
    "\n",
    "def sample_image_generation(\n",
    "    model,\n",
    "    noise_scheduler,\n",
    "    num_generate_images,\n",
    "    random_seed,\n",
    "    num_timesteps,\n",
    "    device,\n",
    "    accelerator,\n",
    "):\n",
    "    pipeline = DDPMPipeline(\n",
    "        unet=accelerator.unwrap_model(model), scheduler=noise_scheduler\n",
    "    )\n",
    "\n",
    "\n",
    "    images = pipeline(\n",
    "        batch_size=num_generate_images,\n",
    "        generator=torch.manual_seed(random_seed),\n",
    "        num_inference_steps=num_timesteps,\n",
    "       \n",
    "    ).images\n",
    " \n",
    "    \n",
    "\n",
    "    # Transform images to tensor and normalize\n",
    "    transform = preprocess\n",
    "\n",
    "    transformed_images = torch.stack([transform(image) for image in images]).to(device)\n",
    "    return transformed_images\n",
    "\n",
    "\n",
    "def calculate_fid(\n",
    "    model,\n",
    "    dataloader_real,\n",
    "    num_generated_images,\n",
    "    noise_scheduler,\n",
    "    random_seed,\n",
    "    num_timesteps,\n",
    "    device,\n",
    "    accelerator,\n",
    "):\n",
    "    \"\"\"Calculate FID score for real and generated images.\"\"\"\n",
    "    # Load InceptionV3 model\n",
    "    inception = inception_v3(pretrained=True, transform_input=False)\n",
    "    inception.fc = nn.Identity()  # Remove the last fully connected layer\n",
    "    inception.to(device)\n",
    "\n",
    "    # Get activations for real images\n",
    "    real_activations = get_activations(inception, dataloader_real, device, key=\"images\")\n",
    "\n",
    "    # Generate images and get activations for generated images\n",
    "    generated_images = sample_image_generation(\n",
    "        model,\n",
    "        noise_scheduler,\n",
    "        num_generated_images,\n",
    "        random_seed,\n",
    "        num_timesteps,\n",
    "        device,\n",
    "        accelerator,\n",
    "    )\n",
    "    \n",
    "    generated_dataset = TensorDataset(generated_images)\n",
    "    generated_dataloader = DataLoader(generated_dataset, batch_size=32, shuffle=False)\n",
    "    generated_activations = get_activations(\n",
    "        inception, generated_dataloader, device, key=0\n",
    "    )\n",
    "\n",
    "    # Calculate statistics\n",
    "    mu_real, sigma_real = calculate_statistics(real_activations)\n",
    "    mu_generated, sigma_generated = calculate_statistics(generated_activations)\n",
    "\n",
    "    # Calculate FID\n",
    "    fid_score = calculate_frechet_distance(\n",
    "        mu_real, sigma_real, mu_generated, sigma_generated\n",
    "    )\n",
    "    return fid_score\n",
    "\n",
    "\n",
    "transform = preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3c2d8eb32f40a485fab4d38ecf1105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EPOCHS:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7843a3cc64664d6d9eb6e78433b13986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef135136e31e4500bd96831a2bfc63c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eee6162a29d40fba80137babe8094ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ba7fcc1a36433c912b7d83c6135706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH: 1: 0.9806\n",
      "Train Learning Rate EPOCH: 1: 3.8000000000000005e-06\n",
      "FID Score EPOCH: 1: 297.3026\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a912f0e27e242fba3ad7167e0f19dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39802f97c5b4247b74a9bf1a47b6663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10917ac4910944688de59284aed27a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe4dd6877314273b7ca2cf61d95d316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH: 2: 0.5210\n",
      "Train Learning Rate EPOCH: 2: 7.600000000000001e-06\n",
      "FID Score EPOCH: 2: 288.8741\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4aaac3e84cc4128995d64fa6a42fec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510c1fa836984261bc8f6217bcc666bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc9a8b2ee4214930adcdf313be375a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e9ea4802974c4a86f0242e846efb7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH: 3: 0.1903\n",
      "Train Learning Rate EPOCH: 3: 9.995529414369582e-06\n",
      "FID Score EPOCH: 3: 274.3082\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae70b39fbfc48769f04cf6219833a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288fb6bed16e417ca80aea6d5534a091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77b958825314baba21c6d5f05f71cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8f54699ce048429e8b689938d03994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH: 4: 0.1222\n",
      "Train Learning Rate EPOCH: 4: 9.938441702975689e-06\n",
      "FID Score EPOCH: 4: 267.5508\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b7b0d806444e8a8d40dbbac6968be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a99dd5d58f64c58bcb90924dda5828b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4656fddfbe3b4823bf61f7fcde1cd732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16e83b4616224fd5ad64ac112a4b6c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH: 5: 0.1026\n",
      "Train Learning Rate EPOCH: 5: 9.816354005237583e-06\n",
      "FID Score EPOCH: 5: 264.1939\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ecb0f905ba46438a51b7484293141c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52cbb373e9114a92b9b8b5e2ae8b886e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23bc2f0e85b4facbc4d039431641f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a7eac788884297bf141af79b2810d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH: 6: 0.0911\n",
      "Train Learning Rate EPOCH: 6: 9.630873244788884e-06\n",
      "FID Score EPOCH: 6: 258.3952\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c30585ec4bf4e5a9132f6c50f0c4930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4e8db7130d46eaae123a8fd4a80b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba6813c50034bdf9efa4a44d8ac9bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a9c82e3c294687b8ed50c90c5dbe6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH: 7: 0.0828\n",
      "Train Learning Rate EPOCH: 7: 9.384440727535666e-06\n",
      "FID Score EPOCH: 7: 252.3250\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e4e0154df040f99538ab87e9e7c7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c2b5696aead47c1aaa32d68134e52fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65756e615a3e425e9a135104fd0ae5aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9265090edbeb4b42a5ccf86e3a43dd75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH: 8: 0.0764\n",
      "Train Learning Rate EPOCH: 8: 9.080300009081025e-06\n",
      "FID Score EPOCH: 8: 243.0449\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe27df3be504203be385fe873c7a654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78026210588040dca6f0e09829c207d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258f4c9c441341b782e5a94c48ed7bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985c5742b45347ecad4d47afc7bc14b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH: 9: 0.0714\n",
      "Train Learning Rate EPOCH: 9: 8.722454202903923e-06\n",
      "FID Score EPOCH: 9: 234.5610\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1de42cc581042aba9f4ab1870ad1add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM_GENERATE_IMAGES_FID = len(train_dataloader)\n",
    "\n",
    "for model, unet_size in zip(models, [\"small\", \"mid\", \"big\"]):\n",
    "    for learning_rate in [LEARNING_RATE / 10, LEARNING_RATE, LEARNING_RATE * 10]:\n",
    "        for optimizer_type in [\"Adam\", \"SGD\"]:\n",
    "            if optimizer_type == \"Adam\":\n",
    "                optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "            elif optimizer_type == \"SGD\":\n",
    "                optimizer = SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "            training_loss = []\n",
    "            frechet_inception_distance = []\n",
    "\n",
    "            lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer=optimizer,\n",
    "                num_warmup_steps=500,\n",
    "                num_training_steps=len(train_dataloader) * NUM_EPOCHS,\n",
    "            )\n",
    "            \n",
    "            noise_scheduler = DDPMScheduler(num_train_timesteps=NUM_TIMESTEPS)\n",
    "\n",
    "            accelerator = Accelerator(\n",
    "                mixed_precision=MIXED_PRECISION,\n",
    "                gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "            )\n",
    "\n",
    "            model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
    "                model, optimizer, train_dataloader, lr_scheduler\n",
    "            )\n",
    "\n",
    "            start = timeit.default_timer()\n",
    "\n",
    "            for epoch in tqdm(range(NUM_EPOCHS), position=0, leave=True, desc=\"EPOCHS\"):\n",
    "\n",
    "                model.train()\n",
    "\n",
    "                train_running_loss = 0\n",
    "\n",
    "                for idx, batch in enumerate(\n",
    "                    tqdm(train_dataloader, position=0, desc=\"BATCHES\", leave=False)\n",
    "                ):\n",
    "\n",
    "                    clean_images = batch[\"images\"].to(device)\n",
    "\n",
    "                    noise = torch.randn(clean_images.shape).to(device)\n",
    "\n",
    "                    last_batch_size = len(clean_images)\n",
    "\n",
    "                    timesteps = torch.randint(\n",
    "                        0,\n",
    "                        noise_scheduler.config.num_train_timesteps,\n",
    "                        (last_batch_size,),\n",
    "                    ).to(device)\n",
    "\n",
    "                    noisy_images = noise_scheduler.add_noise(\n",
    "                        clean_images, noise, timesteps\n",
    "                    )\n",
    "\n",
    "                    with accelerator.accumulate(model):\n",
    "\n",
    "                        noise_pred = model(noisy_images, timesteps, return_dict=False)[\n",
    "                            0\n",
    "                        ]\n",
    "                        loss = F.mse_loss(noise_pred, noise)\n",
    "                        accelerator.backward(loss)\n",
    "\n",
    "                        accelerator.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                        optimizer.step()\n",
    "                        lr_scheduler.step()\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                    train_running_loss += loss.item()\n",
    "                train_loss = train_running_loss / (idx + 1)\n",
    "\n",
    "                training_loss.append(train_loss)\n",
    "                fid_score = calculate_fid(\n",
    "                    model,\n",
    "                    train_dataloader,\n",
    "                    NUM_GENERATE_IMAGES_FID,\n",
    "                    noise_scheduler,\n",
    "                    RANDOM_SEED,\n",
    "                    NUM_TIMESTEPS,\n",
    "                    device,\n",
    "                    accelerator,\n",
    "                )\n",
    "\n",
    "                frechet_inception_distance.append(fid_score)\n",
    "\n",
    "                train_learning_rate = lr_scheduler.get_last_lr()[0]\n",
    "\n",
    "                print(\"-\" * 30)\n",
    "\n",
    "                print(f\"Train Loss EPOCH: {epoch+1}: {train_loss:.4f}\")\n",
    "\n",
    "                print(f\"Train Learning Rate EPOCH: {epoch+1}: {train_learning_rate}\")\n",
    "\n",
    "                print(f\"FID Score EPOCH: {epoch+1}: {fid_score:.4f}\")\n",
    "\n",
    "                print(\"-\" * 30)\n",
    "\n",
    "            stop = timeit.default_timer()\n",
    "\n",
    "            print(f\"Training Time: {stop-start:.2f}s\")\n",
    "\n",
    "            # save model with date and time in a folder\n",
    "            os.makedirs(\"models\", exist_ok=True)\n",
    "            time = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "            model_path = f\"models/{time}\"\n",
    "            os.makedirs(model_path, exist_ok=True)\n",
    "            torch.save(model.state_dict(), f\"{model_path}/model.pth\")\n",
    "            torch.save(optimizer.state_dict(), f\"{model_path}/optimizer.pth\")\n",
    "            torch.save(lr_scheduler.state_dict(), f\"{model_path}/lr_scheduler.pth\")\n",
    "            torch.save(noise_scheduler, f\"{model_path}/noise_scheduler.pth\")\n",
    "\n",
    "            metadata = {\n",
    "                \"IMG_SIZE\": IMG_SIZE,\n",
    "                \"BATCH_SIZE\": BATCH_SIZE,\n",
    "                \"LEARNING_RATE\": LEARNING_RATE,\n",
    "                \"NUM_EPOCHS\": NUM_EPOCHS,\n",
    "                \"NUM_GENERATE_IMAGES\": NUM_GENERATE_IMAGES,\n",
    "                \"NUM_TIMESTEPS\": NUM_TIMESTEPS,\n",
    "                \"MIXED_PRECISION\": MIXED_PRECISION,\n",
    "                \"GRADIENT_ACCUMULATION_STEPS\": GRADIENT_ACCUMULATION_STEPS,\n",
    "                \"losses\": training_loss,\n",
    "                \"fid_scores\": frechet_inception_distance,\n",
    "                \"dataset\": f\"square{IMG_SIZE}_random{str(DATASET_PERCENTAGE)}\",\n",
    "                \"UNET_size\": unet_size,\n",
    "                \"optimizer\": optimizer_type,\n",
    "\n",
    "            }\n",
    "\n",
    "            json.dump(metadata, open(f\"{model_path}/metadata.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
