{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on https://github.com/uygarkurt/DDPM-Image-Generation/blob/main/DDPM_Image_Generartion.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.models import inception_v3\n",
    "from torchvision.transforms import ToTensor, Resize, Normalize, Compose\n",
    "\n",
    "\n",
    "from diffusers import UNet2DModel, DDPMScheduler, DDPMPipeline\n",
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import timeit\n",
    "import json\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "\n",
    "# ignore UserWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "IMG_SIZE = 96\n",
    "DATASET_PERCENTAGE = 0.005\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 25\n",
    "NUM_GENERATE_IMAGES = 9\n",
    "NUM_TIMESTEPS = 500\n",
    "MIXED_PRECISION = \"fp16\"\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9fc6754b4d46c997d2661d316afa13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "local_dataset_path = f\"data/square{IMG_SIZE}_random{str(DATASET_PERCENTAGE)}/\"\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=local_dataset_path)\n",
    "dataset = dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(examples):\n",
    "    images = [preprocess(image.convert(\"RGB\")) for image in examples[\"image\"]]\n",
    "    return {\"images\": images}\n",
    "\n",
    "\n",
    "dataset.set_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_small = UNet2DModel(\n",
    "    sample_size=IMG_SIZE,\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    layers_per_block=1,\n",
    "    block_out_channels=(64, 64, 128, 128, 256),\n",
    "    down_block_types=(\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"AttnDownBlock2D\",\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"AttnUpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "    ),\n",
    ")\n",
    "model_small = model_small.to(device)\n",
    "\n",
    "model_mid = UNet2DModel(\n",
    "    sample_size=IMG_SIZE,\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    layers_per_block=2,\n",
    "    block_out_channels=(128, 128, 256, 256, 512, 512),\n",
    "    down_block_types=(\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"AttnDownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"UpBlock2D\",\n",
    "        \"AttnUpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "    ),\n",
    ")\n",
    "model_mid = model_mid.to(device)\n",
    "\n",
    "\n",
    "model_big = UNet2DModel(\n",
    "    sample_size=IMG_SIZE,\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    layers_per_block=3,\n",
    "    block_out_channels=(128, 256, 256, 512, 512, 1024, 1024),\n",
    "    down_block_types=(\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"AttnDownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"AttnUpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "    ),\n",
    ")\n",
    "model_big = model_big.to(device)\n",
    "models = [model_small, model_mid, model_big]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2):\n",
    "    \"\"\"Calculate the FrÃ©chet Distance between two multivariate Gaussians.\"\"\"\n",
    "    covmean, _ = sqrtm(sigma1 @ sigma2, disp=False)\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "\n",
    "    diff = mu1 - mu2\n",
    "    return diff @ diff + np.trace(sigma1 + sigma2 - 2 * covmean)\n",
    "\n",
    "\n",
    "def get_activations(model, dataloader, device, key):\n",
    "    \"\"\"Get activations of the dataset images using the InceptionV3 model.\"\"\"\n",
    "    model.eval()\n",
    "    activations = []\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Calculating activations\", leave=False):\n",
    "        images = batch[key].to(device)\n",
    "        with torch.no_grad():\n",
    "            preds = model(images)\n",
    "        activations.append(preds.cpu().numpy())\n",
    "\n",
    "    activations = np.concatenate(activations, axis=0)\n",
    "    return activations\n",
    "\n",
    "\n",
    "def calculate_statistics(activations):\n",
    "    \"\"\"Calculate mean and covariance matrix of activations.\"\"\"\n",
    "    mu = np.mean(activations, axis=0)\n",
    "    sigma = np.cov(activations, rowvar=False)\n",
    "    return mu, sigma\n",
    "\n",
    "\n",
    "def sample_image_generation(\n",
    "    model,\n",
    "    noise_scheduler,\n",
    "    num_generate_images,\n",
    "    random_seed,\n",
    "    num_timesteps,\n",
    "    device,\n",
    "    accelerator,\n",
    "):\n",
    "    pipeline = DDPMPipeline(\n",
    "        unet=accelerator.unwrap_model(model), scheduler=noise_scheduler\n",
    "    )\n",
    "\n",
    "\n",
    "    images = pipeline(\n",
    "        batch_size=num_generate_images,\n",
    "        generator=torch.manual_seed(random_seed),\n",
    "        num_inference_steps=num_timesteps,\n",
    "       \n",
    "    ).images\n",
    " \n",
    "    \n",
    "\n",
    "    # Transform images to tensor and normalize\n",
    "    transform = preprocess\n",
    "\n",
    "    transformed_images = torch.stack([transform(image) for image in images]).to(device)\n",
    "    return transformed_images\n",
    "\n",
    "\n",
    "def calculate_fid(\n",
    "    model,\n",
    "    dataloader_real,\n",
    "    num_generated_images,\n",
    "    noise_scheduler,\n",
    "    random_seed,\n",
    "    num_timesteps,\n",
    "    device,\n",
    "    accelerator,\n",
    "):\n",
    "    \"\"\"Calculate FID score for real and generated images.\"\"\"\n",
    "    # Load InceptionV3 model\n",
    "    inception = inception_v3(pretrained=True, transform_input=False)\n",
    "    inception.fc = nn.Identity()  # Remove the last fully connected layer\n",
    "    inception.to(device)\n",
    "\n",
    "    # Get activations for real images\n",
    "    real_activations = get_activations(inception, dataloader_real, device, key=\"images\")\n",
    "\n",
    "    # Generate images and get activations for generated images\n",
    "    generated_images = sample_image_generation(\n",
    "        model,\n",
    "        noise_scheduler,\n",
    "        num_generated_images,\n",
    "        random_seed,\n",
    "        num_timesteps,\n",
    "        device,\n",
    "        accelerator,\n",
    "    )\n",
    "    \n",
    "    generated_dataset = TensorDataset(generated_images)\n",
    "    generated_dataloader = DataLoader(generated_dataset, batch_size=32, shuffle=False)\n",
    "    generated_activations = get_activations(\n",
    "        inception, generated_dataloader, device, key=0\n",
    "    )\n",
    "\n",
    "    # Calculate statistics\n",
    "    mu_real, sigma_real = calculate_statistics(real_activations)\n",
    "    mu_generated, sigma_generated = calculate_statistics(generated_activations)\n",
    "\n",
    "    # Calculate FID\n",
    "    fid_score = calculate_frechet_distance(\n",
    "        mu_real, sigma_real, mu_generated, sigma_generated\n",
    "    )\n",
    "    return fid_score\n",
    "\n",
    "\n",
    "transform = preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNET Size: small, Learning Rate: 1e-05, Optimizer: Adam\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060fa8a2953a4fe2a6f54bf2e782fbeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EPOCHS:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e49ad03642604d85ae0265e708d522f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e9bd23ac434d2bb191ab92eae28655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166570859b0e4953a457fb2839150062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb427a81063941fab1186ae4e9df714a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH: 1: 1.0566\n",
      "Train Learning Rate EPOCH: 1: 1.9000000000000002e-06\n",
      "FID Score EPOCH: 1: 317.4737\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde277f3848c4de6be25125715aa93f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH: 2: 0.9059\n",
      "Train Learning Rate EPOCH: 2: 3.8000000000000005e-06\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa5a2e1453a45d59edcceef243b252e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH: 3: 0.6551\n",
      "Train Learning Rate EPOCH: 3: 5.7e-06\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73cb97ddb5774f34a9efeab951b15a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH: 4: 0.3965\n",
      "Train Learning Rate EPOCH: 4: 7.600000000000001e-06\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4926147e8790499eb82ec92ee6edad50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95860bf610bc408687954b835854fb96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32553db4dbea43e8ac2a6feccd6d7653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d093c874b68f46f0b7b65ed6d3f14369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH: 5: 0.2295\n",
      "Train Learning Rate EPOCH: 5: 9.5e-06\n",
      "FID Score EPOCH: 5: 295.1799\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c945a4bd59e74c65a744cda94409f373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH: 6: 0.1656\n",
      "Train Learning Rate EPOCH: 6: 9.965649316309178e-06\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696f54cfb2064db683738fb3c2f9c4c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH: 7: 0.1379\n",
      "Train Learning Rate EPOCH: 7: 9.81013835793043e-06\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bccff0888f2d44d3baa7836d5e79f547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH: 8: 0.1193\n",
      "Train Learning Rate EPOCH: 8: 9.53301304678419e-06\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0c067c5513487ba0c9f3dfb8058d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663fe5d075014a07a06f1a86580e2631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fbed2b7875249ce86cde1a5485beb80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144810020783485a9d7913619db6f72d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH: 9: 0.1117\n",
      "Train Learning Rate EPOCH: 9: 9.141279920488021e-06\n",
      "FID Score EPOCH: 9: 281.4528\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0a58ffd10844218222962f42761600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH: 10: 0.1078\n",
      "Train Learning Rate EPOCH: 10: 8.644843137107058e-06\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d82d35eb35f4ae6ad8a2f4fa0500b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH: 11: 0.1032\n",
      "Train Learning Rate EPOCH: 11: 8.05625406909846e-06\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf19b74328fe446c8faa21f477220bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH: 12: 0.0940\n",
      "Train Learning Rate EPOCH: 12: 7.390393967940962e-06\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d974a86953547a6b64847b6798efbe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ee5ec2780746c0b6e039444e224df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5032744dab72404c91be3e0949f58718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c45733048714bf7af54196e0d7b509c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH: 13: 0.0923\n",
      "Train Learning Rate EPOCH: 13: 6.664097722614934e-06\n",
      "FID Score EPOCH: 13: 274.1357\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a62949c9f14ed0ba5f243d9bfb56e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH: 14: 0.0918\n",
      "Train Learning Rate EPOCH: 14: 5.8957282244179125e-06\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dacd43769c9436fa708826e6e84f70e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH: 15: 0.0902\n",
      "Train Learning Rate EPOCH: 15: 5.1047120994167855e-06\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd5a0dc0fd845c89277bd6421d1ff56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH: 16: 0.0831\n",
      "Train Learning Rate EPOCH: 16: 4.31104854657681e-06\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1047966d5aa248b0b42319db10f74bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90d2b8c16e6426cb02fcbee603de505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating activations:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2883053efadc492586c60509f565a4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for n_seeds in range(5):\n",
    "    for model, unet_size in zip(models, [\n",
    "        \"small\", \n",
    "        \"mid\", \n",
    "        \"big\"\n",
    "        ]):\n",
    "        for learning_rate in [\n",
    "            LEARNING_RATE / 10, \n",
    "            LEARNING_RATE, \n",
    "            LEARNING_RATE * 10\n",
    "            ]:\n",
    "            for optimizer_type in [\n",
    "                \"Adam\", \n",
    "                # \"SGD\"\n",
    "                ]:\n",
    "                \n",
    "                \n",
    "                print(f\"UNET Size: {unet_size}, Learning Rate: {learning_rate}, Optimizer: {optimizer_type}\")\n",
    "\n",
    "\n",
    "                if optimizer_type == \"Adam\":\n",
    "                    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "                elif optimizer_type == \"SGD\":\n",
    "                    optimizer = SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "                training_loss = []\n",
    "                frechet_inception_distance = []\n",
    "                frechet_inception_distance_epochs = []\n",
    "\n",
    "                lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "                    optimizer=optimizer,\n",
    "                    num_warmup_steps=500,\n",
    "                    num_training_steps=len(train_dataloader) * NUM_EPOCHS,\n",
    "                )\n",
    "                \n",
    "                noise_scheduler = DDPMScheduler(num_train_timesteps=NUM_TIMESTEPS)\n",
    "\n",
    "                accelerator = Accelerator(\n",
    "                    mixed_precision=MIXED_PRECISION,\n",
    "                    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "                )\n",
    "\n",
    "                model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
    "                    model, optimizer, train_dataloader, lr_scheduler\n",
    "                )\n",
    "\n",
    "                start = timeit.default_timer()\n",
    "\n",
    "                for epoch in tqdm(range(NUM_EPOCHS), position=0, leave=True, desc=\"EPOCHS\"):\n",
    "\n",
    "                    def seed_worker(worker_id):\n",
    "                        worker_seed = torch.initial_seed() % 2**32\n",
    "                        np.random.seed(worker_seed)\n",
    "                        random.seed(worker_seed)\n",
    "\n",
    "                    g = torch.Generator()\n",
    "                    g.manual_seed(n_seeds)\n",
    "\n",
    "                    train_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, worker_init_fn=seed_worker, generator=g)\n",
    "\n",
    "\n",
    "                    model.train()\n",
    "\n",
    "                    train_running_loss = 0\n",
    "\n",
    "                    for idx, batch in enumerate(\n",
    "                        tqdm(train_dataloader, position=0, desc=\"BATCHES\", leave=False)\n",
    "                    ):\n",
    "\n",
    "                        clean_images = batch[\"images\"].to(device)\n",
    "\n",
    "                        noise = torch.randn(clean_images.shape).to(device)\n",
    "\n",
    "                        last_batch_size = len(clean_images)\n",
    "\n",
    "                        timesteps = torch.randint(\n",
    "                            0,\n",
    "                            noise_scheduler.config.num_train_timesteps,\n",
    "                            (last_batch_size,),\n",
    "                        ).to(device)\n",
    "\n",
    "                        noisy_images = noise_scheduler.add_noise(\n",
    "                            clean_images, noise, timesteps\n",
    "                        )\n",
    "\n",
    "                        with accelerator.accumulate(model):\n",
    "\n",
    "                            noise_pred = model(noisy_images, timesteps, return_dict=False)[\n",
    "                                0\n",
    "                            ]\n",
    "                            loss = F.mse_loss(noise_pred, noise)\n",
    "                            accelerator.backward(loss)\n",
    "\n",
    "                            accelerator.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                            optimizer.step()\n",
    "                            lr_scheduler.step()\n",
    "                            optimizer.zero_grad()\n",
    "\n",
    "                        train_running_loss += loss.item()\n",
    "                    train_loss = train_running_loss / (idx + 1)\n",
    "\n",
    "                    training_loss.append(train_loss)\n",
    "                    if epoch % 4 == 0 or epoch == NUM_EPOCHS - 1:\n",
    "                        fid_score = calculate_fid(\n",
    "                            model,\n",
    "                            train_dataloader,\n",
    "                            len(train_dataloader),\n",
    "                            noise_scheduler,\n",
    "                            RANDOM_SEED,\n",
    "                            NUM_TIMESTEPS,\n",
    "                            device,\n",
    "                            accelerator,\n",
    "                        )\n",
    "\n",
    "                        frechet_inception_distance.append(fid_score)\n",
    "                        frechet_inception_distance_epochs.append(epoch)\n",
    "\n",
    "                    train_learning_rate = lr_scheduler.get_last_lr()[0]\n",
    "\n",
    "                    print(\"-\" * 30)\n",
    "\n",
    "                    print(f\"Train Loss EPOCH: {epoch+1}: {train_loss:.4f}\")\n",
    "\n",
    "                    print(f\"Train Learning Rate EPOCH: {epoch+1}: {train_learning_rate}\")\n",
    "\n",
    "                    if epoch % 4 == 0 or epoch == NUM_EPOCHS - 1:\n",
    "                        print(f\"FID Score EPOCH: {epoch+1}: {fid_score:.4f}\")\n",
    "\n",
    "                    print(\"-\" * 30)\n",
    "\n",
    "                stop = timeit.default_timer()\n",
    "\n",
    "                print(f\"Training Time: {stop-start:.2f}s\")\n",
    "\n",
    "                # save model with date and time in a folder\n",
    "                os.makedirs(\"models\", exist_ok=True)\n",
    "                time_ = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "                model_path = f\"models/ddpm/hypers/{time_}-{unet_size}-{optimizer_type}-{str(learning_rate)}-{n_seeds}-{DATASET_PERCENTAGE}-{IMG_SIZE}\"\n",
    "                os.makedirs(model_path, exist_ok=True)\n",
    "                \n",
    "              \n",
    "\n",
    "                torch.save(model.state_dict(), f\"{model_path}/model.pth\")\n",
    "                torch.save(optimizer.state_dict(), f\"{model_path}/optimizer.pth\")\n",
    "                torch.save(lr_scheduler.state_dict(), f\"{model_path}/lr_scheduler.pth\")\n",
    "                torch.save(noise_scheduler, f\"{model_path}/noise_scheduler.pth\")\n",
    "\n",
    "                metadata = {\n",
    "                    \"IMG_SIZE\": IMG_SIZE,\n",
    "                    \"BATCH_SIZE\": BATCH_SIZE,\n",
    "                    \"LEARNING_RATE\": LEARNING_RATE,\n",
    "                    \"NUM_EPOCHS\": NUM_EPOCHS,\n",
    "                    \"NUM_GENERATE_IMAGES\": NUM_GENERATE_IMAGES,\n",
    "                    \"NUM_TIMESTEPS\": NUM_TIMESTEPS,\n",
    "                    \"MIXED_PRECISION\": MIXED_PRECISION,\n",
    "                    \"GRADIENT_ACCUMULATION_STEPS\": GRADIENT_ACCUMULATION_STEPS,\n",
    "                    \"losses\": training_loss,\n",
    "                    \"fid_scores\": frechet_inception_distance,\n",
    "                    \"fid_scores_epochs\": frechet_inception_distance_epochs,\n",
    "                    \"dataset\": f\"square{IMG_SIZE}_random{str(DATASET_PERCENTAGE)}\",\n",
    "                    \"UNET_size\": unet_size,\n",
    "                    \"optimizer\": optimizer_type,\n",
    "                    'seed': n_seeds,\n",
    "\n",
    "\n",
    "                }\n",
    "\n",
    "                with open(f\"{model_path}/metadata.json\", \"w\") as f:\n",
    "                    json.dump(metadata, f)\n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
